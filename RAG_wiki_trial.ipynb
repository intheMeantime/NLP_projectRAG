{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhMCta6KU4Yv"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/cookbooks/upstage/Solar-Full-Stack LLM-101/05_3_OracleDB.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG6F1kAYU4Yx"
   },
   "source": [
    "# RAG + Wikipedia (for MMLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vnLzEVF8CysE"
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "file = open(\"info/api.txt\", \"r\")\n",
    "api_key = file.read()\n",
    "file.close()\n",
    "file = open(\"info/path.txt\", \"r\")\n",
    "data_path = file.read()\n",
    "file.close()\n",
    "file = open(\"info/user.txt\", \"r\") \n",
    "user = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read samples.csv file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    prompts = data['prompts']\n",
    "    answers = data['answers']\n",
    "    # returns two lists: prompts and answers\n",
    "    return prompts, answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. build DB (using Wikipida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is the main topic & specific topic of query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, answers = read_data(os.path.join(data_path, 'mmlu_pro.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompts</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUESTION0) The symmetric group $S_n$ has $\\n\\f...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUESTION1) Let V be the set of all real polyno...</td>\n",
       "      <td>(H)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUESTION2) Let A be the set of all ordered pai...</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUESTION3) A tank initially contains a salt so...</td>\n",
       "      <td>(I)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUESTION4) A total of 30 players will play bas...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12097</th>\n",
       "      <td>QUESTION12252) A hot mild steel rod is placed ...</td>\n",
       "      <td>(J)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>QUESTION12253) The cost of making the correct ...</td>\n",
       "      <td>(H)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12099</th>\n",
       "      <td>QUESTION12254) Consider the evaporation of liq...</td>\n",
       "      <td>(F)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12100</th>\n",
       "      <td>QUESTION12255) Air (100°F, 1atm) is flowing at...</td>\n",
       "      <td>(I)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12101</th>\n",
       "      <td>QUESTION12256) The frequency range of a commer...</td>\n",
       "      <td>(F)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompts answers\n",
       "0      QUESTION0) The symmetric group $S_n$ has $\\n\\f...     (A)\n",
       "1      QUESTION1) Let V be the set of all real polyno...     (H)\n",
       "2      QUESTION2) Let A be the set of all ordered pai...     (E)\n",
       "3      QUESTION3) A tank initially contains a salt so...     (I)\n",
       "4      QUESTION4) A total of 30 players will play bas...     (B)\n",
       "...                                                  ...     ...\n",
       "12097  QUESTION12252) A hot mild steel rod is placed ...     (J)\n",
       "12098  QUESTION12253) The cost of making the correct ...     (H)\n",
       "12099  QUESTION12254) Consider the evaporation of liq...     (F)\n",
       "12100  QUESTION12255) Air (100°F, 1atm) is flowing at...     (I)\n",
       "12101  QUESTION12256) The frequency range of a commer...     (F)\n",
       "\n",
       "[12102 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = pd.read_csv(data_path+'mmlu_pro.csv')\n",
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Answer according to the conditions.\n",
    "    1. Return the broad topic and specific topic for the given [Sentence].\n",
    "    2. Respond with ONLY the two words that correspond to [Answer].\n",
    "    3. The answer format is AS FOLLOW.\n",
    "    4. Do not output any other characters.\n",
    "\n",
    "    Q : Return the topic of the given sentence as two keyword, one as a broad topic, and one as a specific term.\n",
    "        [Sentence] : The _________ of a number is its logarithm to the base of the mathematical constant e.\n",
    "    [Answer] math,logarithm\n",
    "\n",
    "    Q : Return the topic of the given sentence as two keyword, one as a broad topic, and one as a specific term.\n",
    "        [Sentence] : Who is the person making the argument that “reason seems to be able to prove that free will cannot be a causally efficacious part of the world (because all of nature is deterministic) and yet that it must be such a cause”?\n",
    "    [Answer] philosophy,Immanuel Kant\n",
    "\n",
    "    Q : Return the topic of the given sentence as two keyword, one as a broad topic, and one as a specific term.        \n",
    "        [Sentence] : {question}\n",
    "    [Answer]\n",
    "\n",
    "    '''\n",
    "\n",
    ")\n",
    "chain_2shot = prompt_template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Answer according to the conditions.\n",
    "    1. Return the broad topic and specific topic for the given [Sentence].\n",
    "    2. Respond with ONLY the two words that correspond to [Answer].\n",
    "    3. The answer format is AS FOLLOW.\n",
    "    4. Do not output any other characters.\n",
    "\n",
    "    [Sentence] Who is the person making the argument that “reason seems to be able to prove that free will cannot be a causally efficacious part of the world (because all of nature is deterministic) and yet that it must be such a cause”?\n",
    "    [Answer] philosophy,Immanuel Kant\n",
    "\n",
    "    [Sentence] {question}\n",
    "    [Answer] \n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    ")\n",
    "chain_1shot = prompt_template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Return the topic of the given sentence ONLY as two word, one as a broad topic, and one as a specific topic.\n",
    "    Return TWO word like (a broad topic ,a specific topic).\n",
    "\n",
    "    Sentence : {question}\n",
    "    topic: \n",
    "\n",
    "    Do not output any other characters.\n",
    "    \n",
    "    '''\n",
    "\n",
    ")\n",
    "chain_zero = prompt_template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = testdata.prompts\n",
    "responses = []\n",
    "for query in querys[:30] :\n",
    "    response = chain_1shot.invoke({\"question\": query.partition('(A)')[0]}) # 선지 전까지 받아오기\n",
    "    responses.append(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mathematics,group theory',\n",
       " 'mathematics,calculus',\n",
       " 'mathematics,combinatorics',\n",
       " '\\n    \\n    [Answer] physics,engineering',\n",
       " 'math,division',\n",
       " 'nasal cavity',\n",
       " 'embryology,hyoid bone',\n",
       " 'medical,catheter',\n",
       " 'medicine,cannulation',\n",
       " 'virology,parvoviruses',\n",
       " 'astronomy,optics',\n",
       " 'Astrophysics, Oort Cloud',\n",
       " 'astronomy,refracting telescope',\n",
       " 'physics,optics',\n",
       " 'physics,electricity',\n",
       " 'social media, corporate social responsibility, social media, sustainability goals',\n",
       " 'ethics,management',\n",
       " 'democratic,inclusive',\n",
       " 'Email',\n",
       " 'purchasing department',\n",
       " 'biology,Arthropods',\n",
       " 'biology,genetics',\n",
       " 'biology,enzyme',\n",
       " 'biochemical synthesis',\n",
       " 'biology,cell division',\n",
       " 'chemistry,spectroscopy',\n",
       " 'chemistry,hydrides',\n",
       " 'organic chemistry,acid anhydride',\n",
       " 'chemistry,acid',\n",
       " 'chemistry,acid-base equilibrium']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 멍청한 solar를 위해 프롬프트를 나누다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_upstage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatUpstage\n\u001b[0;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatUpstage(api_key \u001b[38;5;241m=\u001b[39m \u001b[43mapi_key\u001b[49m)\n\u001b[1;32m      7\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m chain_1shott \u001b[38;5;241m=\u001b[39m prompt_template \u001b[38;5;241m|\u001b[39m llm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api_key' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Answer according to the conditions.\n",
    "    1. Return the broad topic for the given [Sentence] as is.\n",
    "    2. Respond with ONLY One Word that correspond to [Answer].\n",
    "    3. The answer format is AS FOLLOW.\n",
    "    4. Do NOT output ANY OTHER characters.\n",
    "\n",
    "    [Sentence] The _________ of a number is its logarithm to the base of the mathematical constant e.\n",
    "    [Answer] math,logarithm\n",
    "\n",
    "    [Sentence] {question}\n",
    "    [Answer] \n",
    "\n",
    "    '''\n",
    "\n",
    ")\n",
    "chain_1shott = prompt_template | llm\n",
    "\n",
    "querys = testdata.prompts\n",
    "responses = []\n",
    "for query in querys[:30] :\n",
    "    response = chain_1shott.invoke({\"question\": query.partition('(A)')[0]}) # 선지 전까지 받아오기\n",
    "    responses.append(response.content)\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_upstage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatUpstage\n\u001b[0;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatUpstage(api_key \u001b[38;5;241m=\u001b[39m \u001b[43mapi_key\u001b[49m)\n\u001b[1;32m      7\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m chain_1shott \u001b[38;5;241m=\u001b[39m prompt_template \u001b[38;5;241m|\u001b[39m llm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api_key' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Answer according to the conditions.\n",
    "    1. Return the SPECIFIC topic for the given [Sentence].\n",
    "    2. Respond with ONLY One Word that correspond to [Answer].\n",
    "    3. The answer format is AS FOLLOW.\n",
    "    4. Do NOT output ANY OTHER characters.\n",
    "\n",
    "    [Sentence] Who is the person making the argument that “reason seems to be able to prove that free will cannot be a causally efficacious part of the world (because all of nature is deterministic) and yet that it must be such a cause”?\n",
    "    [Answer] Immanuel Kant\n",
    "\n",
    "    [Sentence] {question}\n",
    "    [Answer] \n",
    "    \n",
    "\n",
    "    '''\n",
    "\n",
    ")\n",
    "chain_1shott = prompt_template | llm\n",
    "\n",
    "querys = testdata.prompts\n",
    "responses = []\n",
    "for query in querys[:30] :\n",
    "    response = chain_1shott.invoke({\"question\": query.partition('(A)')[0]}) # 선지 전까지 받아오기\n",
    "    responses.append(response.content)\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한 단어로 요약시켜버리기 ㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To solve this task, we can follow these steps:\\n\\n1. Identify the main word in the given sentence.\\n2. Remove any additional words or phrases that are not part of the main word.\\n3. Return the main word as the answer.\\n\\nHere\\'s the Python code to accomplish this:\\n\\n```python\\n# Step 4: Given the sentence, identify the main word and remove any additional words or phrases.\\nsentence = \"The symmetric group $S_n$ has $\\\\\\\\factorial{n}$ elements, hence it is not true that $S_{10}$ has 10 elements. Find the characteristic of the ring 2Z.\"\\n\\n# Step 5: Remove any additional words or phrases that are not part of the main word.\\nmain_word = \"characteristic\"\\n\\n# Step 6: Return the main word as the answer.\\nmain_word\\n```',\n",
       " 'The main word from the given sentence is \"mathematics\".',\n",
       " 'To solve this problem, we can use a simple approach:\\n\\n1. Split the sentence into words.\\n2. Get the first word.\\n3. Return the first word.\\n\\nHere is the Python code to solve this problem:\\n\\n```python\\ndef main_word(sentence):\\n    words = sentence.split()\\n    return words[0]\\n\\nsentence = \"QUESTION2) Let A be the set of all ordered pairs of integers (m, n) such that 7m + 12n = 22. What is the greatest negative number in the set B = {m + n : (m, n) \\\\in A}?\"\\nprint(main_word(sentence))\\n```\\n\\nWhen you run this code, it will return \"QUESTION2\".',\n",
       " 'The main word from the given sentence is \"philosophy\".',\n",
       " 'The main word from the given sentence is \"basketball\".',\n",
       " 'The main word from the given sentence is \"cavity\".',\n",
       " '[Answer] embryology',\n",
       " 'The main word from the given sentence \"QUESTION7) What is the difference between a male and a female catheter?\" is \"catheter\".',\n",
       " 'The main word from the given sentence is \"cannulate\".',\n",
       " 'To solve this problem, I will use the Natural Language Toolkit (NLTK) to tokenize the given sentences and then find the main word(s) in each sentence.\\n\\nHere\\'s the Python code to do that:\\n```python\\nimport nltk\\n\\ndef find_main_word(sentence):\\n    # Tokenize the sentence\\n    tokens = nltk.word_tokenize(sentence)\\n\\n    # Remove punctuation and convert to lowercase\\n    tokens = [token.lower() for token in tokens if token.isalpha()]\\n\\n    # Find the main word(s) in the sentence\\n    main_word = nltk.pos_tag(tokens)\\n    main_word = [word for word, pos in main_word if pos == \\'NN\\']\\n\\n    return main_word[0] if main_word else None\\n\\n# Test the function with the given sentences\\nsentence = \"QUESTION9) Why are parvoviruses a highly impactful parasite?\"\\nmain_word = find_main_word(sentence)\\nmain_word\\n```',\n",
       " 'The main word from the given sentence is: \"telescope\".',\n",
       " '    Return a main word from the given sentence.\\n\\n    [Sentence] QUESTION11) Where do most short-period comets come from and how do we know?\\n    [Answer] comets',\n",
       " 'To solve this task, we need to extract the main word from the given sentence. We can achieve this by following these steps:\\n\\n1. Read the given sentence.\\n2. Remove any punctuation and convert the sentence to lowercase.\\n3. Split the sentence into individual words.\\n4. Find the word with the highest frequency in the sentence.\\n5. Return this word as the main word.\\n\\nHere is the Python code to implement this solution:\\n```python\\nimport re\\nfrom collections import Counter\\n\\ndef find_main_word(sentence):\\n    # Remove punctuation and convert to lowercase\\n    sentence = re.sub(r\\'[^\\\\w\\\\s]\\', \\'\\', sentence).lower()\\n    # Split the sentence into individual words\\n    words = sentence.split()\\n    # Count the frequency of each word\\n    word_counts = Counter(words)\\n    # Find the word with the highest frequency\\n    main_word = word_counts.most_common(1)[0][0]\\n    # Return the main word\\n    return main_word\\n\\nsentence = \"QUESTION12) A refracting telescope consists of two converging lenses separated by 100 cm. The eye-piece lens has a focal length of 20 cm. The angular magnification of the telescope is\"\\nmain_word = find_main_word(sentence)\\nmain_word\\n```',\n",
       " \"To solve this problem, we need to find the main word from the given sentence. We can use Natural Language Processing (NLP) techniques to achieve this. Here are the steps:\\n\\n1. Tokenize the sentence into individual words.\\n2. Remove any stop words (common words like 'is', 'the', 'and', etc.) from the sentence.\\n3. Find the most frequent word in the remaining words.\\n4. Return the most frequent word as the main word.\\n\\nHere is the Python code to implement this:\\n\\n```python\\nimport re\\nfrom collections import Counter\\n\\ndef find_main_word(sentence):\\n    # Tokenize the sentence into individual words\\n    words = re.findall(r'\\\\b\\\\w+\\\\b', sentence)\\n\\n    # Remove stop words\\n    stop_words = set(['is', 'the', 'and', 'that', 'which', 'what', 'who', 'how', 'why', 'where', 'when', 'can', 'could', 'may', 'might', 'will', 'would', 'shall', 'should', 'if', 'else', 'or', 'nor', 'so', 'but', 'yet', 'also', 'then', 'after', 'before', 'since', 'because', 'although', 'as', 'at', 'by', 'for', 'with', 'from', 'to', 'upon', 'of', 'about', 'after', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'against', 'between', 'into', 'through', 'during', 'before', 'since', 'after', 'again', 'again\\n```\",\n",
       " 'Here is a Python function that returns the main word from a given sentence:\\n\\n```python\\nimport re\\n\\ndef main_word(sentence):\\n    words = re.findall(r\\'\\\\b\\\\w+\\\\b\\', sentence)\\n    return max(words, key=len)\\n\\n# Test the function\\nprint(main_word(\"Who is the person making the argument that \\\\\"reason seems to be able to prove that free will cannot be a causally efficacious part of the world and yet that it must be such a cause\\\\\"\"))\\nprint(main_word(\"QUESTION14) A microwave oven is connected to an outlet, 120 V, and draws a current of 2 amps. At what rate is energy being used by the microwave oven?\"))\\n```\\n\\nThis function uses regular expressions to find all words in the sentence, and then returns the longest word. The regular expression `\\\\b\\\\w+\\\\b` matches any word boundary (`\\\\b`), followed by one or more word characters (`\\\\w+`), followed by another word boundary (`\\\\b`). This matches any word in the sentence. The `max` function is used to find the longest word, with the `key` argument set to `len` to specify that the length of each word should be used for comparison.',\n",
       " '[Answer] policy',\n",
       " 'The main word from the given sentence is \"ethics\".',\n",
       " 'To solve this task, I will use the NLTK library in Python to perform tokenization and stemming on the given sentence. After that, I will return the most common word in the sentence.\\n\\nHere\\'s the Python code to solve the task:\\n\\n```python\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import PorterStemmer\\nfrom collections import Counter\\n\\ndef get_main_word(sentence):\\n    # Tokenization\\n    tokens = nltk.word_tokenize(sentence)\\n\\n    # Remove stopwords\\n    stop_words = set(stopwords.words(\\'english\\'))\\n    tokens = [token for token in tokens if token not in stop_words]\\n\\n    # Stemming\\n    stemmer = PorterStemmer()\\n    tokens = [stemmer.stem(token) for token in tokens]\\n\\n    # Count the frequency of each word\\n    word_counts = Counter(tokens)\\n\\n    # Get the most common word\\n    main_word = word_counts.most_common(1)[0][0]\\n\\n    return main_word\\n\\nsentence = \"QUESTION17) How can organisational structures that are characterised by democratic and inclusive styles of management be described?\"\\nmain_word = get_main_word(sentence)\\nprint(main_word)\\n```\\n\\nLet\\'s run this code to get the main word from the given sentence.\\n```python\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import PorterStemmer\\nfrom collections import Counter\\n\\ndef get_main_word(sentence):\\n    # Tokenization\\n    tokens = nltk.word_tokenize(sentence)\\n\\n    # Remove stopwords\\n    stop_words = set(stopwords.words(\\'english\\'))\\n    tokens = [token for token in tokens if token not in stop_words]\\n\\n    # Stemming\\n    stemmer = PorterStemmer()\\n    tokens = [stemmer.stem(token) for token in tokens]\\n\\n    # Count the frequency of each word\\n    word_counts = Counter(tokens)\\n\\n    # Get the most common word\\n    main_word = word_counts.most_common(1)[0][0]\\n\\n    return main_word\\n\\nsentence = \"QUESTION17) How can organisational structures that are characterised by democratic and inclusive styles of management be described?\"\\nmain_word = get_main_word(sentence)\\nmain_word\\n```',\n",
       " 'The main word from the given sentence is \"advertising\".',\n",
       " 'The main word from the given sentence is \"buying\".',\n",
       " 'To solve this task, we need to find a way to identify the main or key word in the given sentence. One approach could be to look for the most frequently occurring word in the sentence, as it is likely to be a common word or a stopword. Another approach could be to use a Natural Language Processing (NLP) library, such as NLTK or SpaCy, to identify the main verb in the sentence, as the verb often represents the main action or idea of the sentence.\\n\\nHere is a Python code using NLTK to identify the main verb in the given sentence:\\n```python\\nimport nltk\\n\\n# Given sentence\\nsentence = \"QUESTION20) Which of the following represents an accurate statement concerning arthropods?\"\\n\\n# Tokenize the sentence into words\\nwords = nltk.word_tokenize(sentence)\\n\\n# Identify the main verb in the sentence\\nmain_verb = None\\nfor word in words:\\n    if nltk.pos_tag([word])[0][1] in [\\'VB\\', \\'VBD\\', \\'VBG\\', \\'VBN\\', \\'VBP\\', \\'VBZ\\']:\\n        main_verb = word\\n        break\\n\\n# Print the main verb\\nprint(main_verb)\\n```\\nThis code will output \"represents\", which is the main verb in the given sentence.',\n",
       " 'To solve this task, we will follow these steps:\\n\\nStep 1: We need to find a method to extract the main word from a given sentence.\\nStep 2: We can start by tokenizing the sentence to separate it into individual words.\\nStep 3: Then, we can identify the word that appears most frequently in the sentence as the main word.\\nStep 4: We also need to take into account the case when the sentence has multiple main words.\\nStep 5: We will implement a function to tokenize the sentence and count the frequency of each word, and then return the word with the highest frequency as the main word.\\n\\n\\n```python\\n# Step 6: We need a way to extract the main word from a given sentence.\\ndef extract_main_word(sentence):\\n    # Step 7: Tokenize the sentence to separate it into individual words.\\n    words = sentence.split()\\n    # Step 8: Initialize a dictionary to store the frequency of each word.\\n    word_count = {}\\n    # Step 9: Iterate through each word in the sentence and count its frequency.\\n    for word in words:\\n        if word in word_count:\\n            word_count[word] += 1\\n        else:\\n            word_count[word] = 1\\n    # Step 10: Return the word with the highest frequency as the main word.\\n    main_word = max(word_count, key=word_count.get)\\n    return main_word\\n\\n# Step 11: Test the function with the given sentence and expected answer.\\nsentence = \"Who is the person making the argument that “reason seems to be able to prove that free will cannot be a causally efficacious part of the world and yet that it must be such a cause”?\"\\nanswer = extract_main_word(sentence)\\nprint(answer)  # Output: philosophy\\n```',\n",
       " 'To solve this problem, I will use the Natural Language Toolkit (NLTK) in Python. NLTK is a library that provides a suite of text processing tools.\\n\\nHere is a Python function that can be used to solve the problem:\\n\\n```python\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\n\\ndef get_main_word(sentence):\\n    # Tokenize the sentence into words\\n    words = word_tokenize(sentence)\\n\\n    # Remove stop words\\n    stop_words = set(stopwords.words(\\'english\\'))\\n    words = [word for word in words if word.lower() not in stop_words]\\n\\n    # Return the most frequent word\\n    return max(set(words), key=words.count)\\n\\nsentence = \"QUESTION22) A mutation in a bacterial enzyme changed a previously polar amino acid into a nonpolar amino acid. This amino acid was located at a site distant from the enzyme’s active site. How might this mutation alter the enzyme’s substrate specificity?\"\\nprint(get_main_word(sentence))\\n```\\n\\nWhen you run this code, it will return the word \"amino\". This is the most frequent word in the sentence after removing stop words.',\n",
       " 'To solve this problem, we need to identify the main word from the given sentence. Here\\'s a Python function that does just that:\\n\\n```python\\ndef main_word(sentence):\\n    words = sentence.split()\\n    return words[0]\\n\\nsentence = \"QUESTION23) Which of the following is not a way to form recombinant DNA?\"\\nprint(main_word(sentence))\\n```\\n\\nThis function splits the sentence into words using the `split()` function, and then returns the first word, which is assumed to be the main word. When you run this function with the given sentence, it will return \"QUESTION23\".',\n",
       " 'There seems to be a mistake in the task description. You mentioned to return a main word from the given sentence, but you only provided the second sentence without the main word. Could you please provide the main word for the second sentence?',\n",
       " 'To solve this problem, we can use Natural Language Processing (NLP) techniques to extract the main topic or subject of the given sentence. Here\\'s a Python code using NLTK library to perform this task:\\n\\n```python\\nimport nltk\\nfrom nltk.corpus import wordnet\\n\\ndef main_word(sentence):\\n    # Convert the sentence to lowercase\\n    sentence = sentence.lower()\\n\\n    # Tokenize the sentence\\n    words = nltk.word_tokenize(sentence)\\n\\n    # Remove punctuation\\n    words = [word for word in words if word.isalpha()]\\n\\n    # Find the most frequent word\\n    main_word = max(set(words), key=words.count)\\n\\n    return main_word\\n\\nsentence = \"QUESTION25) Predict the number of lines in the EPR spectrum of a solution of 13C-labelled methyl radical (13CH3•), assuming the lines do not overlap.\"\\nprint(main_word(sentence))\\n```\\n\\nThe output will be:\\n\\n```\\nlines\\n```\\n\\nThis code first tokenizes the sentence into individual words, then removes punctuation and non-alphabetical characters. Finally, it finds the most frequent word in the sentence, which is considered as the main word.\\n\\nPlease note that this is a simple approach and may not work perfectly for all sentences, especially those with complex structures or multiple main topics. For more accurate results, you may need to use more advanced NLP techniques, such as topic modeling or sentiment analysis.',\n",
       " '[Answer] chemistry',\n",
       " 'To solve this problem, we can use Natural Language Processing (NLP) techniques to identify the main word in the given sentence. Here is a Python solution using the NLTK library:\\n\\n```python\\nimport nltk\\nfrom nltk.corpus import stopwords\\n\\ndef main_word(sentence):\\n    # Tokenize the sentence into words\\n    words = nltk.word_tokenize(sentence)\\n\\n    # Remove punctuation\\n    words = [word.strip(\\'.,!?\\') for word in words]\\n\\n    # Remove stopwords\\n    stop_words = set(stopwords.words(\\'english\\'))\\n    words = [word for word in words if word not in stop_words]\\n\\n    # Return the most frequent word\\n    word_freq = nltk.FreqDist(words)\\n    main_word = word_freq.max()\\n\\n    return main_word\\n\\nsentence = \"QUESTION27) Which of the following is considered an acid anhydride?\"\\nprint(main_word(sentence))\\n```\\n\\nThis code first tokenizes the sentence into words, then removes punctuation and stopwords (common words like \"is\", \"the\", \"and\", etc.). Finally, it counts the frequency of each word and returns the most frequent word, which is considered the main word.\\n\\nPlease note that this is a simple approach and may not work perfectly for all sentences, especially those with complex structures or multiple main words. Also, the result may vary depending on the context of the sentence.',\n",
       " 'The main word from the given sentence is \"acid\".',\n",
       " 'To solve this problem, we can use Natural Language Processing (NLP) techniques to extract the main word from the given sentence. Here is a Python code that uses the NLTK library to tokenize the sentence and select the most frequent word as the main word.\\n```python\\nimport nltk\\nfrom collections import Counter\\n\\ndef get_main_word(sentence):\\n    # Tokenize the sentence\\n    tokens = nltk.word_tokenize(sentence)\\n    # Count the frequency of each word\\n    word_counts = Counter(tokens)\\n    # Select the most frequent word as the main word\\n    main_word = word_counts.most_common(1)[0][0]\\n    return main_word\\n\\nsentence = \"QUESTION29) A solution contains 2.00 mole of acetic acid, CH3COOH, and 1.00 mole of calcium acetate, Ca(CH3COO)2. The solution is able to resist the addition of a small amount of strong acid or strong base with only minor changes in the pH of the solution. Larger quantities of strong acid or strong base can cause a significant change in pH. How many moles of nitric acid, HNO3, may be added before the pH begins to change significantly?\"\\n\\nmain_word = get_main_word(sentence)\\nprint(main_word)\\n```\\nThis code will output the main word from the given sentence, which is \"acid\".']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Retrun a main word from the given sentence.\n",
    "\n",
    "    [Sentence] Who is the person making the argument that “reason seems to be able to prove that free will cannot be a causally efficacious part of the world and yet that it must be such a cause”?\n",
    "    [Answer] philosophy\n",
    "\n",
    "    [Sentence] {question}\n",
    "    [Answer] \n",
    "    \n",
    "\n",
    "    Return with only A word!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "    '''\n",
    "\n",
    ")\n",
    "\n",
    "chain_summ = prompt_template | llm\n",
    "\n",
    "querys = testdata.prompts\n",
    "responses = []\n",
    "for query in querys[:30] :\n",
    "    response = chain_summ.invoke({\"question\": query.partition('(A)')[0]}) # 선지 전까지 받아오기\n",
    "    responses.append(response.content)\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zer-shot으로 노선 개같이 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Algebra',\n",
       " 'Mathematics',\n",
       " 'Mathematics.',\n",
       " 'Chemical_Engineering',\n",
       " 'Mathematics',\n",
       " 'Anatomy',\n",
       " 'Anatomy',\n",
       " 'Medical devices',\n",
       " 'Medicine',\n",
       " 'Viruses',\n",
       " 'Physics',\n",
       " 'Astronomy',\n",
       " 'Optics',\n",
       " 'Physics',\n",
       " 'Electricity',\n",
       " 'Sustainability',\n",
       " 'Ethics',\n",
       " 'Management.',\n",
       " 'Advertising',\n",
       " 'purchasing',\n",
       " 'Arthropods',\n",
       " 'Genetics',\n",
       " 'Mutation',\n",
       " 'Biology',\n",
       " 'Biology',\n",
       " 'Spectroscopy',\n",
       " 'Chemistry',\n",
       " 'Chemistry',\n",
       " 'Chemistry',\n",
       " '\\nAcid-Base Reaction']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Answer according to the conditions.\n",
    "    1. Return the broad topic for the given [Sentence].\n",
    "    2. Respond with ONLY One Word that correspond to [Answer].\n",
    "    3. Do NOT output ANY OTHER characters.\n",
    "\n",
    "    [Sentence] {question}\n",
    "    The broad topic is\n",
    "\n",
    "    '''\n",
    "\n",
    ")\n",
    "chain_1shott = prompt_template | llm\n",
    "\n",
    "querys = testdata.prompts\n",
    "broad_topics = []\n",
    "for query in querys[:30] :\n",
    "    response = chain_1shott.invoke({\"question\": query.partition('(A)')[0]}) # 선지 전까지 받아오기\n",
    "    broad_topics.append(response.content)\n",
    "\n",
    "broad_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link to Wikipedia\n",
    "\n",
    "답변으로 받아온 두 개의 토픽 -> wikipedia 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "# user는 내 아이디 같은 거\n",
    "wiki_wiki = wikipediaapi.Wikipedia(f'{user}', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Algebra',\n",
       " 'calculus',\n",
       " 'Algebra.',\n",
       " 'CHEMISTRY',\n",
       " 'Division.',\n",
       " 'sella turcica',\n",
       " 'first pharyngeal arch',\n",
       " 'Anatomy',\n",
       " 'Medicine',\n",
       " 'DNA',\n",
       " 'Magnification',\n",
       " 'Oort Cloud',\n",
       " 'Telescope',\n",
       " 'PHYSICS',\n",
       " 'Power',\n",
       " '보이콧',\n",
       " 'Ethics.',\n",
       " 'Democratic.',\n",
       " 'Email',\n",
       " 'buyers',\n",
       " 'Insects',\n",
       " 'homozygous',\n",
       " 'Mutation.',\n",
       " 'Transfection.',\n",
       " 'Mitosis.',\n",
       " 'Spectroscopy',\n",
       " 'Silicon.',\n",
       " 'Carboxylic',\n",
       " 'acid',\n",
       " 'Acid-Base Equilibrium']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: False\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: True\n",
      " Broad Topic Page - Exists: False\n"
     ]
    }
   ],
   "source": [
    "for broad in responses :\n",
    "    wiki_broad = wiki_wiki.page(f'{broad}')\n",
    "    print(\" Broad Topic Page - Exists: %s\" % wiki_broad.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page - Exists: True\n"
     ]
    }
   ],
   "source": [
    "# 해당 topic에 해당하는 Wikipedia가 있는지 확인하기\n",
    "wiki_broad = wiki_wiki.page(f'{broad}')\n",
    "print(\" Broad Topic Page - Exists: %s\" % wiki_broad.exists())\n",
    "\n",
    "wiki_speci = wiki_wiki.page(f'{specific}')\n",
    "print(\" Specific Topic Page - Exists: %s\" % wiki_speci.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page - Title: Hip hop music\n",
      "102199\n"
     ]
    }
   ],
   "source": [
    "# topicd에 해당하는 Wikipedia의 title과 본문 길이 출력\n",
    "print(\"Page - Title: %s\" % wiki_broad.title)\n",
    "print(len(wiki_broad.text))\n",
    "\n",
    "# topic에 해당하는 Wikipedia의 title과 본문 길이 출력\n",
    "print(\"Page - Title: %s\" % wiki_speci.title)\n",
    "print(len(wiki_speci.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Split (chunking Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzSLZ0UUzIRs",
    "outputId": "775ed2fc-56b5-4144-e06c-5160a260f00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 14\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (Language, RecursiveCharacterTextSplitter,)\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 받아온 Wikipedia를 split함수에 적용할 수 있도록 변환\n",
    "docs = wiki_query.text\n",
    "docs = Document(page_content=docs)\n",
    "\n",
    "# 2. Split **** (hyper param)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    chunk_size=10000, chunk_overlap=2500, language=Language.HTML\n",
    ")\n",
    "splits = text_splitter.split_documents([docs])\n",
    "print(\"Splits:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsRe-ivuzKeJ",
    "outputId": "54c3286c-8b48-4a28-8423-6b936e54746b"
   },
   "outputs": [],
   "source": [
    "print(splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking된 context 확인하기\n",
    "splits[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. query-context matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "# 쿼리 전용 임베딩 모델\n",
    "query_embeddings = UpstageEmbeddings(api_key=api_key, model=\"solar-embedding-1-large-query\")\n",
    "\n",
    "# 문장 전용 임베딩 모델\n",
    "passage_embeddings = UpstageEmbeddings(api_key=api_key, model=\"solar-embedding-1-large-passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt engineering (for answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ZNtcrvTLzT0h",
    "outputId": "c72a4a60-5e9f-42d3-e06a-7ce23dcffe01"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = api_key)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    '''\n",
    "    \n",
    "    Please provide most correct answer from the following context.\n",
    "    If the answer is not present in the context, please Answer \"The information is NOT present in the context.\"\n",
    "    \n",
    "    The Answer format is as follow (do not explain) : \n",
    "    Answer: (D) keyword.\n",
    "    ---\n",
    "    \n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Answer :\n",
    "    ---\n",
    "        \n",
    "    '''\n",
    "\n",
    ")\n",
    "chain = prompt_template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3+4. 하나로 통합\n",
    "# chunked Wikipedia -> embedding \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "chunk = []\n",
    "for index in range(0,len(splits)) : # context 받아오기\n",
    "    chunk.append(splits[index].page_content)\n",
    "\n",
    "responses = []\n",
    "for prompt in prompts[:1] : # 질문 받아오기 \n",
    "    embedded_query = query_embeddings.embed_query(prompt.split('\\n')[0])\n",
    "    embedded_documents = passage_embeddings.embed_documents(chunk)\n",
    "\n",
    "    # 질문(embedded_query):\n",
    "    similarity = np.array(embedded_query) @ np.array(embedded_documents).T\n",
    "\n",
    "    # 유사도 기준 내림차순 정렬\n",
    "    sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]\n",
    "\n",
    "    # QA\n",
    "    response = chain.invoke({\"question\": prompt, \"context\": sorted_idx[0]})\n",
    "    responses.append(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zy80OSXF88Gj",
    "outputId": "a1a20aff-fca1-4f60-a1db-27db1818d5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To answer the question, I will need more information about what specific aspect of the COVID-19 pandemic you would like me to discuss. Please provide more details or specify the topic you would like me to cover.\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for i in responses:\n",
    "    print(i)\n",
    "    print('-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZAq6pyGhXLq"
   },
   "outputs": [],
   "source": [
    "# funcion to extract an answer from response\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_answer(response):\n",
    "    \"\"\"\n",
    "    extracts the answer from the response using a regular expression.\n",
    "    expected format: \"[ANSWER]: (A) convolutional networks\"\n",
    "\n",
    "    if there are any answers formatted like the format, it returns None.\n",
    "    \"\"\"\n",
    "    pattern = r\"\\[ANSWER\\]:\\s*\\((A|B|C|D|E)\\)\"  # Regular expression to capture the answer letter and text\n",
    "    match = re.search(pattern, response)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1) # Extract the letter inside parentheses (e.g., A)\n",
    "    else:\n",
    "        return extract_again(response)\n",
    "\n",
    "def extract_again(response):\n",
    "    pattern = r\"\\b[A-J]\\b(?!.*\\b[A-J]\\b)\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItZapouNdenq",
    "outputId": "7ad3125f-921f-42e7-bfd0-dff15236f065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "To answer the question, I will need more information about what specific aspect of the COVID-19 pandemic you would like me to discuss. Please provide more details or specify the topic you would like me to cover.\n",
      "generated answer: I, answer: (A)\n",
      "\n",
      "acc: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for answer, response in zip(answers, responses):\n",
    "    print(\"-\"*10)\n",
    "    generated_answer = extract_answer(response)\n",
    "    print(response)\n",
    "    # check\n",
    "    if generated_answer:\n",
    "        print(f\"generated answer: {generated_answer}, answer: {answer}\")\n",
    "    else:\n",
    "        print(\"extraction fail\")\n",
    "\n",
    "\n",
    "    if generated_answer == None:\n",
    "        continue\n",
    "    if generated_answer in answer:\n",
    "        cnt += 1\n",
    "\n",
    "print()\n",
    "print(f\"acc: {(cnt/len(answers))*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
