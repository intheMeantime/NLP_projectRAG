{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhMCta6KU4Yv"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/cookbooks/upstage/Solar-Full-Stack LLM-101/05_3_OracleDB.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG6F1kAYU4Yx"
   },
   "source": [
    "# Retrieval Augmented Generation (RAG) Baseline\n",
    "## Overview  \n",
    "In this time, we will check the baseline code.\n",
    "The goal of this project is to provide students with hands-on experience in handling and enhancing Large Language Models (LLMs) provided by [**Upstage**](https://www.upstage.ai) (Solar).\n",
    "\n",
    "You can use any engineering method for improving benchmark performance excluding direct training (Fine-tuning).\n",
    "\n",
    "*Collecting data directly related to the test set is considered cheating e.g., using MMLU-pro dataset or EWHA.pdf for KB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8AXJLRMnTrU"
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TCOGfdsU4Yy"
   },
   "outputs": [],
   "source": [
    "!pip3 install -qU python-dotenv PyPDF2 langchain langchain-community langchain-core langchain-text-splitters langchain_upstage oracledb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4zxnXJVU4Y2"
   },
   "outputs": [],
   "source": [
    "# Additional Contents : https://wikidocs.net/253106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnLzEVF8CysE"
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "api_key = \"YOUR KEYS\"\n",
    "data_path = \"YOUR PATH\" # folder path containing ewah.pdf and samples.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmCwvoB1zH3H",
    "outputId": "edee142c-257a-48ce-8d3b-4e2fbfa4b081"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_upstage/layout_analysis.py:135: UserWarning: UpstageLayoutAnalysisLoader is deprecated.Please use langchain_upstage.document_parse.UpstageDocumentParseLoader instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_upstage/layout_analysis_parsers.py:160: UserWarning: UpstageLayoutAnalysisParser is deprecated.Please use langchain_upstage.document_parse_parsers.UpstageDocumentParseParser instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "import os\n",
    " \n",
    "UPSTAGE_API_KEY = api_key\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(api_key=UPSTAGE_API_KEY,file_path=os.path.join(data_path, 'ewha.pdf'), output_type=\"text\")\n",
    "\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzSLZ0UUzIRs",
    "outputId": "775ed2fc-56b5-4144-e06c-5160a260f00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 53\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    chunk_size=1000, chunk_overlap=100, language=Language.HTML\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"Splits:\", len(splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsRe-ivuzKeJ",
    "outputId": "54c3286c-8b48-4a28-8423-6b936e54746b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='이화여자대학교 학칙1946. 8. 15. 제정\n",
      "2017. 8. 16. 개정제1장 총칙제1조(목적) 본교는 대한민국의 교육이념과 기독교정신을 바탕으로 하여 학술의 깊은 이론과\n",
      "그 광범하고 정밀한 응용방법을 교수․연구하며, 인격을 도야하여 국가와 인류사회의 발전에\n",
      "공헌할 수 있는 지도여성을 양성함을 목적으로 한다.제2조(명칭) 본교는 이화여자대학교라 부른다.\n",
      "제3조(위치) 본교는 서울특별시 서대문구 이화여대길 52에 둔다. (개정 2013.2.25.)제2장 편제제4조(대학 및 대학원) ① 본교에는 다음 각 호의 대학을 둔다.1. 인문과학대학, 사회과학대학, 자연과학대학, 엘텍공과대학, 음악대학, 조형예술대학, 사범\n",
      "대학, 경영대학, 신산업융합대학, 의과대학, 간호대학, 약학대학, 스크랜튼대학(이하 “각\n",
      "대학”이라 한다) (개정 2016.6.16.)\n",
      "2. 호크마(HOKMA)교양대학\n",
      "② 본교에는 대학원, 국제대학원, 통역번역대학원, 경영전문대학원, 법학전문대학원, 교육대\n",
      "학원, 디자인대학원, 사회복지대학원, 신학대학원, 정책과학대학원, 공연예술대학원, 임상보\n",
      "건융합대학원, 임상치의학대학원, 외국어교육특수대학원을 둔다(이하 “각 대학원”이라 한다).\n",
      "(개정 2016.6.16., 2017.5.15.)\n",
      "[전문개정 2015.11.27.]제5조(학부․학과․전공 및 정원) ① 각 대학, 학부, 학과, 전공 및 모집단위별 입학정원은 별표\n",
      "1과 같다. (개정 2015.5.8., 2016.2.16., 2016.2.26., 2016.5.19., 2017.5.4., 2017.5.15.)② 모집단위별 입학정원의 일부는 입학전형에 따라 2개 이상의 모집단위를 통합하여 모집\n",
      "할 수 있다. (개정 1999.2.9., 2017.5.15.)\n",
      "③ 제2항에 따라 통합된 모집단위로 입학한 학생과 대학 또는 학부 등 광역화된 모집단위\n",
      "로 입학한 학생에 대하여는 일정한 학기와 학점을 이수한 후에 총장의 승인을 얻어 이수할\n",
      "전공을 결정하게 하되 이에 필요한 사항은 총장이 따로 정한다. (개정 2016.2.1' metadata={'total_pages': 54}\n"
     ]
    }
   ],
   "source": [
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qSi7C5xeBVt"
   },
   "outputs": [],
   "source": [
    "# read samples.csv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    prompts = data['prompts']\n",
    "    answers = data['answers']\n",
    "    # returns two lists: prompts and answers\n",
    "    return prompts, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4kuh6HOeqMv"
   },
   "outputs": [],
   "source": [
    "prompts, answers = read_data(os.path.join(data_path, 'samples.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ZNtcrvTLzT0h",
    "outputId": "c72a4a60-5e9f-42d3-e06a-7ce23dcffe01"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_upstage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8992b95cc6aa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_upstage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatUpstage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatUpstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUPSTAGE_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_upstage'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage(api_key = UPSTAGE_API_KEY)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide most correct answer from the following context.\n",
    "    If the answer is not present in the context, please write \"The information is not present in the context.\"\n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "chain = prompt_template | llm\n",
    "\n",
    "responses = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = chain.invoke({\"question\": prompt, \"context\": splits[0]})\n",
    "    responses.append(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zy80OSXF88Gj",
    "outputId": "a1a20aff-fca1-4f60-a1db-27db1818d5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이화여자대학교 학칙에는 영어 및 정보 등에 관한 일정한 기준의 능력이나 자격을 취득한 경우 인정받는 학점에 대한 정보가 없습니다. 따라서, 주어진 선택지 중 어느 것도 정답이 아닙니다.\n",
      "---------\n",
      "이화여자대학교 학칙에 대한 내용이며, LMS 시스템의 초기 비밀번호에 대한 정보는 제공되지 않습니다.\n",
      "---------\n",
      "The information is not present in the context.\n",
      "---------\n",
      "The information is not present in the context.\n",
      "---------\n",
      "문맥에서 답변이 없습니다.\n",
      "---------\n",
      "문맥에서 질문에 대한 답은 제시되어 있지 않습니다.\n",
      "---------\n",
      "The information is not present in the context.\n",
      "---------\n",
      "해당 문맥에서는 법의 기능에 대한 정보가 제공되지 않았습니다.\n",
      "---------\n",
      "The information is not present in the context.\n",
      "---------\n",
      "The information is not present in the context.\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for i in responses:\n",
    "    print(i)\n",
    "    print('-'*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZAq6pyGhXLq"
   },
   "outputs": [],
   "source": [
    "# funcion to extract an answer from response\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_answer(response):\n",
    "    \"\"\"\n",
    "    extracts the answer from the response using a regular expression.\n",
    "    expected format: \"[ANSWER]: (A) convolutional networks\"\n",
    "\n",
    "    if there are any answers formatted like the format, it returns None.\n",
    "    \"\"\"\n",
    "    pattern = r\"\\[ANSWER\\]:\\s*\\((A|B|C|D|E)\\)\"  # Regular expression to capture the answer letter and text\n",
    "    match = re.search(pattern, response)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1) # Extract the letter inside parentheses (e.g., A)\n",
    "    else:\n",
    "        return extract_again(response)\n",
    "\n",
    "def extract_again(response):\n",
    "    pattern = r\"\\b[A-J]\\b(?!.*\\b[A-J]\\b)\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItZapouNdenq",
    "outputId": "7ad3125f-921f-42e7-bfd0-dff15236f065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "이화여자대학교 학칙에는 영어 및 정보 등에 관한 일정한 기준의 능력이나 자격을 취득한 경우 인정받는 학점에 대한 정보가 없습니다. 따라서, 주어진 선택지 중 어느 것도 정답이 아닙니다.\n",
      "extraction fail\n",
      "-----\n",
      "이화여자대학교 학칙에 대한 내용이며, LMS 시스템의 초기 비밀번호에 대한 정보는 제공되지 않습니다.\n",
      "extraction fail\n",
      "-----\n",
      "The information is not present in the context.\n",
      "extraction fail\n",
      "-----\n",
      "The information is not present in the context.\n",
      "extraction fail\n",
      "-----\n",
      "문맥에서 답변이 없습니다.\n",
      "extraction fail\n",
      "-----\n",
      "문맥에서 질문에 대한 답은 제시되어 있지 않습니다.\n",
      "extraction fail\n",
      "-----\n",
      "The information is not present in the context.\n",
      "extraction fail\n",
      "-----\n",
      "해당 문맥에서는 법의 기능에 대한 정보가 제공되지 않았습니다.\n",
      "extraction fail\n",
      "-----\n",
      "The information is not present in the context.\n",
      "extraction fail\n",
      "-----\n",
      "The information is not present in the context.\n",
      "extraction fail\n",
      "\n",
      "acc: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for answer, response in zip(answers, responses):\n",
    "    print(\"-\"*10)\n",
    "    generated_answer = extract_answer(response)\n",
    "    print(response)\n",
    "    # check\n",
    "    if generated_answer:\n",
    "        print(f\"generated answer: {generated_answer}, answer: {answer}\")\n",
    "    else:\n",
    "        print(\"extraction fail\")\n",
    "\n",
    "\n",
    "    if generated_answer == None:\n",
    "        continue\n",
    "    if generated_answer in answer:\n",
    "        cnt += 1\n",
    "\n",
    "print()\n",
    "print(f\"acc: {(cnt/len(answers))*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내가 한 거 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 3 (similarity)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "chunk = []\n",
    "for index in range(0,len(splits)) : # context 받아오기\n",
    "    chunk.append(splits[index].page_content)\n",
    "\n",
    "for prompt in prompts[:5] : # 질문 받아오기 \n",
    "    embedded_query = query_embeddings.embed_query(prompt.split('\\n')[0])\n",
    "    embedded_documents = passage_embeddings.embed_documents(chunk)\n",
    "\n",
    "    # 질문(embedded_query):\n",
    "    similarity = np.array(embedded_query) @ np.array(embedded_documents).T\n",
    "\n",
    "    # 유사도 기준 내림차순 정렬\n",
    "    sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"\\n[Query] {prompt[:10]}\")\n",
    "    print(\"-\" * 10)\n",
    "    for i, idx in enumerate(sorted_idx):\n",
    "        print(f\"[{i}] 유사도: {similarity[idx]:.3f} | 해당 context: {idx}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "euron",
   "language": "python",
   "name": "euron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
